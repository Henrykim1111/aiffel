{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## 4-1. 프로젝트: 인물 모드 문제점 찾기\n",
    "\n",
    "만들면서 뭔가 이상한 점이 느껴지지 않으셨나요? 프로젝트를 통해 찾아봅시다.\n",
    "\n",
    "우선 주요 라이브러리 버전을 확인해 볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib: 사용자가 파이썬의 import 시스템과 상호작용하기 위한 API를 제공하는 내장 라이브러리\n",
    "# 사용자는 import 함수의 구현 내용과, 실행에 필요한 하위 함수들을 이용해 필요에 맞는 임포터를 직접 구현하거나 임포트 관련 기능들을 자유롭게 사용할 수 있음\n",
    "# importlib.metadata: 설치된 패키지 메타 데이터에 대한 접근을 제공하는 라이브러리.\n",
    "# 해당 코드 블럭에서는 importlib.metadata 안에 있는 version() 함수를 이용하여 pixellib 라이브러리의 버전을 확인\n",
    "\n",
    "from importlib.metadata import version\n",
    "import cv2\n",
    "import pixellib\n",
    "\n",
    "print(cv2.__version__)\n",
    "print(version('pixellib'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Step 1. 인물모드 직접 해 보기\n",
    "---\n",
    "여러분의 셀카를 이용해서 오늘 배운 내용을 수행해 봅시다. 아래와 같은 이미지를 얻어야 합니다. 최소 3장 이상의 인물모드 사진을 만들어 봅시다.\n",
    "인물이 주인공이 아닌, 귀여운 고양이에 대한 아웃포커싱 사진도 만들어 볼 수 있을 것입니다. 시맨틱 세그멘테이션 스텝에서 힌트를 찾아봅시다.\n",
    "배경을 blur하는 인물모드 사진이 아니라 배경사진을 다른 이미지로 교체하는 크로마키 배경 합성을 시도해 볼 수도 있을 것입니다. 여러분만의 환상적인 사진을 만들어 보면 어떨까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Step 2. 사진에서 문제점 찾기\n",
    "---\n",
    "그러나 여러분들의 사진에는 무언가 문제점이 있을 것입니다.\n",
    "\n",
    "아래 사진에도 문제점이 몇 가지 있었습니다. 예를 들어 뒤에 걸린 옷이 인물 영역에 포함되어 blur되지 않고 나온다던가 하는 경우입니다. ㅠㅠ\n",
    " 그 외 다른 문제들이 눈에 띄시나요? 아래 사진에는 이상한 점이 최소 2개 이상 더 있습니다. 어떤 문제가 있는지 찾아서 아래 사진처럼 표시해 봅시다.\n",
    "\n",
    "추가로 여러분이 만들어 낸 인물 모드 사진 중 하나에서도 이상한 위치를 찾아 아래 사진처럼 표시해 봅시다. 표시한 이미지들을 jupyter notebook에 포함하여 제출해 주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Step 3. 해결 방법을 제안해 보기\n",
    "---\n",
    "아주 간단히 멋진 카메라 앱 서비스를 만들어 출시할 수 있을 것 같았지만, 지금 같은 완성도로는 어림도 없습니다. 소비자들의 눈높이는 그리 호락호락하지 않고, 엔지니어인 여러분들은 답을 찾아내야 합니다.\n",
    "\n",
    "생각해 볼 만한 주제를 아래에 몇 가지 제시해 봅니다. 아래를 읽어본 후, 여러분이 만든 인물모드 사진의 문제점을 해결할 방안을 정리하여 제안해 주시기 바랍니다.\n",
    "단순히 'XXX 기술을 사용한다.' 정도의 선언적 솔루션이 아니라, 여러분들이 선택한 기술이 DeepLab 모델의 Semantic Segmentation 이 만들어 낸 Mask 영역에 어떻게 적용되어 문제점을 보완하게 되는지의 메커니즘이 포함된 솔루션이어야 합니다.\n",
    "\n",
    "세그멘테이션의 한계\n",
    "\n",
    "Semantic segmentation의 부정확성이 여러 가지 문제를 발생시키는 주요 원인입니다. 피사계심도를 이용한 보케(아웃포커싱) 효과는 말 그대로 심도를 표현하기 때문에 초점이 잡힌 거리를 광학적으로 아주 섬세하게 구별(segmentation) 하지만 이를 따라 한 semantic segmentation 모듈은 정확도가 1.00 이 되지 않는 한 완벽히 구현하기는 힘듭니다.\n",
    "\n",
    "피사계 심도 이해하기\n",
    "\n",
    "우선 피사계심도의 개념부터 명확히 이해해 봅시다.\n",
    "\n",
    "- 아웃포커싱 하는 법 (https://m.blog.naver.com/typs6301/222172333739)\n",
    "- 얕은 피사계 심도 촬영의 이해 (https://www.adobe.com/kr/creativecloud/photography/discover/shallow-depth-of-field.html)\n",
    "\n",
    "3D Camera 활용하기\n",
    "\n",
    "이미지를 2D 방식으로 받아들이는 한계를 넘어 3D로 인식하려는 시도는 꽤 오래전부터 계속되어 왔습니다. 기술도 이제는 상당한 수준에 이르렀는데요. 크게는 스테레오 비전, ToF 방식 등이 자주 사용됩니다.\n",
    " 하드웨어 이미지 센서를 통한 3D 이미징 기술이 많이 발전되었는데요. 아래 참고 자료를 통해 최신 기술을 살펴봐도 좋습니다.\n",
    "\n",
    "- 3D 이미지센서 (https://news.skhynix.co.kr/post/next-gen-3d)\n",
    "\n",
    "소프트웨어 기술 활용하기\n",
    "\n",
    "하드웨어 개발과 생산에는 비용이 많이 들기 때문에 제한된 하드웨어를 이용하면서 소프트웨어로 그 한계를 극복하려는 노력도 많습니다. 구글의 struct2Depth가 대표적인 예일 것 같습니다.\n",
    "\n",
    "- Unsupervised Learning of Depth and Ego-Motion: A Structured Approach (https://sites.google.com/view/struct2depth)\n",
    "\n",
    "딥러닝이 발전한 지금은 더 다양한 기술이 개발되어 있으니 잘 탐색해 보세요.\n",
    "\n",
    "다른 기술과 융합해 보기\n",
    "\n",
    "구글 pixel4에는 IR(적외선) 카메라가 달려있는데요. 물체의 온도를 측정하는 IR 카메라와 3D 이미지는 크게 관련이 없을 것 같지만, 이를 통해 보다 멋진 3d depth sensing이 가능하다는군요.\n",
    "\n",
    "- uDepth: Real-time 3D Depth Sensing on the Pixel 4 (https://research.google/blog/udepth-real-time-3d-depth-sensing-on-the-pixel-4/)\n",
    "\n",
    "이렇게 카메라와 무관한 다른 기술과 융합하는 것도 좋은 해결책이 될 수 있습니다. 한 번 고민해 보세요!\n",
    "\n",
    "이 외에도 다른 방식으로 접근해도 좋습니다. 엔지니어로서 본인이 선택한 솔루션을 잘 설명해 주세요. 가능하다면 순서도(Flow Chart)를 활용하면 좋습니다. 멋진 아이디어를 기대하겠습니다!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 4-2. 실습\n",
    "\n",
    "### 아웃포커싱 인물사진\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pixellib.semantic import semantic_segmentation\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path1 = os.getenv('HOME')+'/aiffel/workplace/240605-human-segmentation-practice/images/human.png'\n",
    "img_orig1 = cv2.imread(img_path1) \n",
    "\n",
    "print(img_orig1.shape)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img_orig1, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.getenv('HOME')+'/aiffel/workplace/240605-human-segmentation-practice/models' \n",
    "\n",
    "model_file = os.path.join(model_dir, 'deeplabv3_xception_tf_dim_ordering_tf_kernels.h5') \n",
    "\n",
    "model_url = 'https://github.com/ayoolaolafenwa/PixelLib/releases/download/1.1/deeplabv3_xception_tf_dim_ordering_tf_kernels.h5' \n",
    "\n",
    "urllib.request.urlretrieve(model_url, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = semantic_segmentation() \n",
    "model.load_pascalvoc_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "segvalues1, output1 = model.segmentAsPascalvoc(img_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_NAMES = [\n",
    "    'background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus',\n",
    "    'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike',\n",
    "    'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tv'\n",
    "]\n",
    "len(LABEL_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(output1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "segvalues1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_id in segvalues1['class_ids']:\n",
    "    print(LABEL_NAMES[class_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = np.zeros((256, 3), dtype = int)\n",
    "ind = np.arange(256, dtype=int)\n",
    "\n",
    "for shift in reversed(range(8)):\n",
    "    for channel in range(3):\n",
    "        colormap[:, channel] |= ((ind >> channel) & 1) << shift\n",
    "    ind >>= 3\n",
    "\n",
    "colormap[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_color1 = (128,128,192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_map1 = np.all(output1==seg_color1, axis=-1) \n",
    "print(seg_map1.shape) \n",
    "plt.imshow(seg_map1, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_show1 = img_orig1.copy()\n",
    "img_mask1 = seg_map1.astype(np.uint8) * 255\n",
    "color_mask1 = cv2.applyColorMap(img_mask1, cv2.COLORMAP_JET)\n",
    "img_show1 = cv2.addWeighted(img_show1, 0.6, color_mask1, 0.4, 0.0)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img_show1, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_orig_blur1 = cv2.blur(img_orig1, (50,50))\n",
    "plt.imshow(cv2.cvtColor(img_orig_blur1, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_mask_color1 = cv2.cvtColor(img_mask1, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "img_bg_mask1 = cv2.bitwise_not(img_mask_color1)\n",
    "\n",
    "img_bg_blur1 = cv2.bitwise_and(img_orig_blur1, img_bg_mask1)\n",
    "plt.imshow(cv2.cvtColor(img_bg_blur1, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_concat1 = np.where(img_mask_color1==255, img_orig1, img_bg_blur1)\n",
    "plt.imshow(cv2.cvtColor(img_concat1, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "- 다리 한 쪽이 뒤쪽에 있어 색깔이 어둡게 잡혀 background로 인식이 되었다.\n",
    "\n",
    "-> 후처리기법을 통해 모델이 예측한 마스크를 개선할 수 있다. 특히, Conditional Random Fields (CRF)를 사용하면 객체 경계에서의 잘못된 분할을 수정할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### 아웃포커싱 동물사진\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path2 = os.getenv('HOME')+'/aiffel/workplace/240605-human-segmentation-practice/images/dog.png'\n",
    "img_orig2 = cv2.imread(img_path2) \n",
    "\n",
    "print(img_orig1.shape)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img_orig2, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "segvalues2, output2 = model.segmentAsPascalvoc(img_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(output2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "segvalues2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_id in segvalues2['class_ids']:\n",
    "    print(LABEL_NAMES[class_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = np.zeros((256, 3), dtype = int)\n",
    "ind = np.arange(256, dtype=int)\n",
    "\n",
    "for shift in reversed(range(8)):\n",
    "    for channel in range(3):\n",
    "        colormap[:, channel] |= ((ind >> channel) & 1) << shift\n",
    "    ind >>= 3\n",
    "\n",
    "colormap[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_color2 = (128,0,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_map2 = np.all(output2==seg_color2, axis=-1) \n",
    "print(seg_map2.shape) \n",
    "plt.imshow(seg_map2, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_show2 = img_orig2.copy()\n",
    "img_mask2 = seg_map2.astype(np.uint8) * 255\n",
    "color_mask2 = cv2.applyColorMap(img_mask2, cv2.COLORMAP_JET)\n",
    "img_show2 = cv2.addWeighted(img_show2, 0.6, color_mask2, 0.4, 0.0)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img_show2, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_orig_blur2 = cv2.blur(img_orig2, (50,50))\n",
    "plt.imshow(cv2.cvtColor(img_orig_blur2, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_mask_color2 = cv2.cvtColor(img_mask2, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "img_bg_mask2 = cv2.bitwise_not(img_mask_color2)\n",
    "\n",
    "img_bg_blur2 = cv2.bitwise_and(img_orig_blur2, img_bg_mask2)\n",
    "plt.imshow(cv2.cvtColor(img_bg_blur2, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_concat2 = np.where(img_mask_color2==255, img_orig2, img_bg_blur2)\n",
    "plt.imshow(cv2.cvtColor(img_concat2, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "- 피사체와 배경의 색차이가 극명하기에 잘 진행되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "### 배경전환 크로마키\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path3 = os.getenv('HOME')+'/aiffel/workplace/240605-human-segmentation-practice/images/human_chrom.png'\n",
    "img_path4 = os.getenv('HOME')+'/aiffel/workplace/240605-human-segmentation-practice/images/background_chrom.png'\n",
    "img_orig3 = cv2.imread(img_path3)\n",
    "img_orig4 = cv2.imread(img_path4)\n",
    "\n",
    "print(img_orig3.shape)\n",
    "print(img_orig4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(img_orig3, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(img_orig4, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "segvalues3, output3 = model.segmentAsPascalvoc(img_path3)\n",
    "segvalues4, output4 = model.segmentAsPascalvoc(img_path4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(output3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(output4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_id in segvalues3['class_ids']:\n",
    "    print(LABEL_NAMES[class_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_id in segvalues4['class_ids']:\n",
    "    print(LABEL_NAMES[class_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_color3 = (128,128,192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_map3 = np.all(output3==seg_color3, axis=-1) \n",
    "print(seg_map3.shape) \n",
    "plt.imshow(seg_map3, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_show3 = img_orig3.copy()\n",
    "img_mask3 = seg_map3.astype(np.uint8) * 255\n",
    "color_mask3 = cv2.applyColorMap(img_mask3, cv2.COLORMAP_JET)\n",
    "img_show3 = cv2.addWeighted(img_show3, 0.6, color_mask3, 0.4, 0.0)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img_show3, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_mask_color3 = cv2.cvtColor(img_mask3, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "img_bg_mask3 = cv2.bitwise_not(img_mask_color3)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img_bg_mask3, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_orig4_resized = cv2.resize(img_orig4, (img_orig3.shape[1], img_orig3.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_concat3 = np.where(img_mask_color3==255, img_orig3, img_orig4_resized)\n",
    "plt.imshow(cv2.cvtColor(img_concat3, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "- 누끼가 잘 따졌다. 만족스럽다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
