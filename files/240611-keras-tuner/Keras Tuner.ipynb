{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Tuner 탬플릿\n",
    "\n",
    "### 오늘의 주제\n",
    "- Keras Tuner\n",
    "- 학습 모니터링 시각화\n",
    "- 모델 학습 과정의 시각적 이해\n",
    "\n",
    "### 오늘의 목표\n",
    "- 모델의 성능을 높히는 다양한 기법을 확인합니다\n",
    "- Keras Tuner의 실습을 진행합니다\n",
    "- 학습 시각화 기법을 익힙니다\n",
    "\n",
    "### 오늘의 미션\n",
    "> 💡 모델의 성능을 높혀보는 방법, 하이퍼파라메터 튜닝을 사용해봅니다\n",
    "\n",
    "- 하이퍼파라메터 튜닝\n",
    "    - 좋은 모델 만들기 위해서는 **좋은 파라메터 찾는 것이 필요합니다**\n",
    "    - 반복 실험으로 좋은 파라메터를 찾을 수 있겠지만, 많은 비용이 발생합니다\n",
    "    - 케라스에서는 최적의 파라메터를 쉽고 빠르게 찾을 수 있는 도구 **Keras Tuner**를 지원합니다\n",
    "    - KerasTuner API\n",
    "        \n",
    "        13장을 학습하며, 다음 [케라스 튜너 튜토리얼](https://keras.io/api/keras_tuner/)을 확인하고, 다음의 내용을 채워봅니다\n",
    "        \n",
    "        - HP 인수\n",
    "            - 하이퍼파라메터 클래스, 탐색 공간**(Search Space)** 내부의 값들과 현재 값 모두를 포함합니다. 보통 이를 HP 인수로 사용합니다.\n",
    "            - 종류\n",
    "                - 모델 하이퍼파라메터 : 히든 레이어 수, 레이어 너비\n",
    "                - 알고리즘 하이퍼파라메터 : optimizer 종류와 learning rate\n",
    "            - **(미션)** 다음의 [예제코드](https://www.tensorflow.org/tutorials/keras/keras_tuner?hl=ko)를 확인하여 HP 인수가 선언된 함수을 찾아보고, 설명해봅시다!\n",
    "                \n",
    "                ```python\n",
    "                # 코드를 여기에 기록 \n",
    "                ```\n",
    "                \n",
    "        - Tuners\n",
    "            - 하이퍼파라메터 탐색 전략을 정하는 클래스로, Oracle에서 받은 hp값으로 모델을 생성, 훈련, 평가하여, 모델을 Oracle에게 제공합니다\n",
    "                - **(미션)** P545에 보다 쉬운 설명이 있습니다. 튜너에 대한 아이디어와 진행 순서를 기록해봅시다!\n",
    "                    - (답을 여기)\n",
    "                - 내장 튜너로는 RandomSearch, [BayesianOptimization](https://data-scientist-brian-kim.tistory.com/88), [Hyperband](https://iyk2h.tistory.com/143)가 있습니다\n",
    "            - **(미션)** 다음의 [예제코드](https://www.tensorflow.org/tutorials/keras/keras_tuner?hl=ko)를 확인하여 Tuner가 선언된 부분을 찾아보고, 설명해봅시다!\n",
    "                \n",
    "                ```python\n",
    "                # 코드를 여기에 기록 \n",
    "                ```\n",
    "                \n",
    "        - Oracles\n",
    "            - **책에는 소개가 안되어 있지만, Tuner 이야기를 하려면 빠질 수 없는 것이 있습니다**  [공식 페이지](https://keras.io/api/keras_tuner/oracles/)\n",
    "            - Oracle은 KerasTuner의 모든 검색 알고리즘에서 사용하는 기본 클래스, 모델 평가 결과를 Tuner에게서 받아 새로운 hp 값을 제공합니다\n",
    "            - 공식 페이지의 base oracle class 설명에서는, trial object를 통해 위의 Tuner간의 정보 교환이 이루어지게 된다고 설명하고 있습니다\n",
    "            - **(미션)** Tuner에 내장된 검색 알고리즘을 간편하게 사용할 수도 있지만, Oracle을 함께 사용할 경우 얻을 수 있는 장점들에 대해 요약해봅시다!\n",
    "        - HyperModels\n",
    "            - 사전 정의된 ‘특정 모델 : ResNet, XceptionNet 등’을 위한 탐색 공간입니다\n",
    "    - **(미션)** 교재의 예시코드와 아래의 Keras.Tuner의 사용 FLOW를 파악하여, Keras Tuner로 학습해봅시다!\n",
    "        1. Search space 정의 \n",
    "            - 조정할 수 있는 하이퍼파라메터를 정의\n",
    "                - 레이어의 수, 너비\n",
    "                - optimizer의 종류\n",
    "                - **(미션)** 또 어떤 것이 있을까요? 나열해봅시다\n",
    "        2. 모델 정의\n",
    "            \n",
    "            모델 빌더 함수 정의하거나, Hyper model 가져와 활용\n",
    "            \n",
    "            1. 모델 빌더 함수 사용\n",
    "                - [예제 코드](https://www.tensorflow.org/tutorials/keras/keras_tuner?hl=ko)\n",
    "                    \n",
    "                    ```python\n",
    "                    def model_builder(hp):\n",
    "                    \t\n",
    "                      model = keras.Sequential()\n",
    "                      model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "                    \n",
    "                      # Tune the number of units in the first Dense layer\n",
    "                      # Choose an optimal value between 32-512\n",
    "                      hp_units = hp.Int('units', min_value = 32, max_value = 512, step = 32)\n",
    "                      model.add(keras.layers.Dense(units = hp_units, activation = 'relu'))\n",
    "                      model.add(keras.layers.Dense(10))\n",
    "                    \n",
    "                      # Tune the learning rate for the optimizer \n",
    "                      # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "                      hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n",
    "                    \n",
    "                      model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
    "                                    loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True), \n",
    "                                    metrics = ['accuracy'])\n",
    "                    \n",
    "                      return model\n",
    "                    ```\n",
    "                    \n",
    "            \n",
    "            b. [HyperModel](https://keras.io/api/keras_tuner/hypermodels/) 정의\n",
    "            \n",
    "            - Keras tuner에서 사전 정의된 모델을 하위 클래스화해서 사용\n",
    "            - HyperResNet, HyperException 등 Tuner에 내장된 모델을 활용할 수 있음\n",
    "            - 혹은 커스터마이즈\n",
    "                \n",
    "                ```python\n",
    "                class SimpleMLP(kt.HyperModel):\n",
    "                    def __init__(self, num_classes):\n",
    "                        self.num_classes = num_classes\n",
    "                \n",
    "                    def build(self, hp):\n",
    "                        units = hp.Int(name=\"units\", min_value=16, max_value=64, step=16)\n",
    "                        model = keras.Sequential([\n",
    "                            layers.Dense(units, activation=\"relu\"),\n",
    "                            layers.Dense(self.num_classes, activation=\"softmax\")\n",
    "                        ])\n",
    "                        optimizer = hp.Choice(name=\"optimizer\", values=[\"rmsprop\", \"adam\"])\n",
    "                        model.compile(\n",
    "                            optimizer=optimizer,\n",
    "                            loss=\"sparse_categorical_crossentropy\",\n",
    "                            metrics=[\"accuracy\"])\n",
    "                        return model\n",
    "                \n",
    "                hypermodel = SimpleMLP(num_classes=10)\n",
    "                ```\n",
    "                \n",
    "        3. Tuner 정의 \n",
    "            - 예시코드\n",
    "                \n",
    "                ```python\n",
    "                tuner = kt.BayesianOptimization(\n",
    "                    build_model,\n",
    "                    objective=\"val_accuracy\",\n",
    "                    max_trials=10, \n",
    "                    executions_per_trial=2,\n",
    "                    directory=\"mnist_kt_test\",\n",
    "                    overwrite=True,\n",
    "                ```\n",
    "                \n",
    "        4. 하이퍼파라메터 검색 수행 및 평가 \n",
    "            - 예시코드\n",
    "                \n",
    "                ```python\n",
    "                tuner.search(img_train, label_train, epochs = 10, \n",
    "                validation_data = (img_test, label_test), \n",
    "                callbacks = [callbacks])\n",
    "                \n",
    "                # 탐색 공간의 요약 정보 확인\n",
    "                tuner.search_space_summary()\n",
    "                \n",
    "                # Get the optimal hyperparameters\n",
    "                best_hps = tuner.get_best_hyperparameters(num_trials = num_trials)\n",
    "                ```\n",
    "                \n",
    "        5. 찾은 하이퍼파라메터로 모델 구성하기\n",
    "            - **(미션)** 예시코드\n",
    "                \n",
    "                ```python\n",
    "                # 코드를 여기에 기록 \n",
    "                ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
